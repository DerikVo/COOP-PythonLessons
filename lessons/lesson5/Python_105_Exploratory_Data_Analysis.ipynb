{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "51dd7a33",
      "metadata": {
        "id": "51dd7a33"
      },
      "source": [
        "<img src=\"https://tinyurl.com/k2t79s6t\" style=\"float: left; margin: 20px; height: 55px\">\n",
        "\n",
        "# Python 105: Data Analytics Salary Analysis\n",
        " _Author: Martin Arroyo_\n",
        "\n",
        "\n",
        "\n",
        "## Scenario\n",
        "You are an analyst working on a new data set that your company acquired for research purposes. It contains salary information for data analytics professionals collected between 2020 and 2022.\n",
        "\n",
        "Management has asked you to do an exploratory analysis of this new data. [Click here to read the email they sent you.](https://docs.google.com/document/d/1J-3SG76KQxj-aeKQ6-ZmRuntsAdoPqC8lMtQPzuhVJQ/edit?usp=sharing)\n",
        "\n",
        "\n",
        "## Task\n",
        "\n",
        "### Part One\n",
        "Clean the `ds_salaries` table using the outline provided below. Use documentation to refresh your memory on syntax. After you're done cleaning, your data should have no null values and no duplicates.\n",
        "### Part Two\n",
        "Complete the analysis using everything we've learned so far in Python 101-104. Ensure that the data is clean, then answer the questions in the code cells under **Part Two**. Use a combination of visuals, tabular data, and written language to answer the questions. **Create at least 3 visuals**.\n",
        "### Part Three\n",
        "After you're done, write a response to your manager's email letting them know that you have completed your assignment. Share any additional insights or findings you may have found in the data, along with:\n",
        "\n",
        "- a copy of your notebook with your code and visuals\n",
        "- the `ds_salaries_clean` table as a `csv` file\n",
        "\n",
        "This should be a professional email response. In this scenario, your pod captain will play the role of manager.\n",
        "\n",
        "<hr />\n",
        "\n",
        "\n",
        "## Tips\n",
        "\n",
        "### Using Python + SQL\n",
        "\n",
        "Since we are connected to a database, you can use a combination of `SQL` and `Python` to answer your questions.\n",
        "\n",
        "To query the database directly, you can use the `%%sql` cell magic at the top of a cell, then write your query below like this:\n",
        "```sql\n",
        "%%sql\n",
        "\n",
        "SELECT * FROM ds_salaries;\n",
        "```\n",
        "\n",
        "Once you have the results you like, copy and paste the query into a `string`, then get your result as a `DataFrame` using `read_sql`:\n",
        "```python\n",
        "query = \"SELECT * FROM ds_salaries\"\n",
        "my_query_df = pd.read_sql(query, con=engine)\n",
        "```\n",
        "\n",
        "### Keep in Mind\n",
        "\n",
        "This is not a client project, nor will this be part of a presentation. It should be neat, but any visuals you make do not need to be fancy.\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "If you get stuck, first do a search for the problem you're trying to solve. More often than not, someone else has encountered a similar issue and you'll be able to find a relatively clear answer. You can also check the documentation of the program you're using. If you find yourself getting frustrated, stop and take a short break. If all else fails, then reach out to another person for help.\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "There may be things here that you don't remember how to do, or maybe there is something you want to do that we haven't covered. Use the resources provided to you in Slack and from the other Python nights, the Python 101-104 notebooks, as well as whatever you can find on the internet to help you.\n",
        "\n",
        "Here are a few to get you started:\n",
        "- [w3schools](https://www.w3schools.com/python/)\n",
        "- [DataCamp Cheat Sheets](https://www.datacamp.com/cheat-sheet)\n",
        "- [Stack Overflow](https://stackoverflow.com/)\n",
        "- [SQL Basics Cheatsheet](https://martinmarroyo.github.io/sqlcheatsheetandresources-coop/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "726c07a6",
      "metadata": {
        "id": "726c07a6"
      },
      "source": [
        "## Connect to the Database and get the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d813af0a",
      "metadata": {
        "id": "d813af0a"
      },
      "source": [
        "Run the following cell to establish the connection to your team's database and get the data (this may take a minute or two to complete):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befffe7d",
      "metadata": {
        "id": "befffe7d"
      },
      "outputs": [],
      "source": [
        "# Install `teachdb` if it's not in the system already\n",
        "from importlib.util import find_spec\n",
        "if not find_spec('teachdb'):\n",
        "    print(\"Installing `teachdb` and its dependencies...\")\n",
        "    !pip install --quiet --upgrade git+https://github.com/freestackinitiative/teachingdb.git\n",
        "    print(\"Successfully installed `teachdb`\")\n",
        "import os\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import sqlalchemy as sql\n",
        "import matplotlib.pyplot as plt\n",
        "from teachdb.teachdb import connect_teachdb\n",
        "\n",
        "# Set configurations for notebook\n",
        "%load_ext sql\n",
        "%config SqlMagic.autopandas = True\n",
        "%config SqlMagic.feedback = False\n",
        "%config SqlMagic.displaycon = False\n",
        "\n",
        "# Load data\n",
        "engine = duckdb.connect(\":memory:\")\n",
        "connect_teachdb(engine, database=\"ds_salaries\")\n",
        "\n",
        "%sql engine\n",
        "\n",
        "# Get the data from the database into a DataFrame\n",
        "ds_salaries = pd.read_sql(\"SELECT * FROM ds_salaries\", con=engine)\n",
        "countries = pd.read_sql(\"SELECT * FROM countries\", con=engine)\n",
        "usd_exchange_rates = pd.read_sql(\"SELECT * FROM usd_exchange_rates\", con=engine)\n",
        "experience_levels = pd.read_sql(\"SELECT * FROM experience_levels\", con=engine)\n",
        "employment_types = pd.read_sql(\"SELECT * FROM employment_types\", con=engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93c2a97",
      "metadata": {
        "id": "d93c2a97"
      },
      "source": [
        "## Part One: Cleaning the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4440bb70",
      "metadata": {
        "id": "4440bb70"
      },
      "source": [
        "Our task is to explore this new dataset, clean it, then answer the questions from management using the data. We haven't seen the data before, so our first step is familiarize ourselves with it.\n",
        "\n",
        "Since the data has not been cleaned, we consider it to be in its \"raw\" form. It's good practice to not modify raw data directly - that way you can revert back to the original state when/if you need to. Let's start by making a copy of `ds_salaries`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e35dc94",
      "metadata": {
        "id": "0e35dc94"
      },
      "outputs": [],
      "source": [
        "ds_salaries_clean = ds_salaries.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_salaries_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "Vu-V2eaOOhq_",
        "outputId": "a0d3051c-2fb7-47c1-fd42-46939609336b"
      },
      "id": "Vu-V2eaOOhq_",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      work_year experience_level employment_type                   job_title  \\\n",
              "0          2020               MI              FT              Data Scientist   \n",
              "1          2020               SE              FT  Machine Learning Scientist   \n",
              "2          2020               SE              FT           Big Data Engineer   \n",
              "3          2020               MI              FT        Product Data Analyst   \n",
              "4          2020               SE              FT   Machine Learning Engineer   \n",
              "...         ...              ...             ...                         ...   \n",
              "1251       2022               MI              FT               Data Engineer   \n",
              "1252       2022               SE              FT              Data Scientist   \n",
              "1253       2022               SE              FT       Data Science Engineer   \n",
              "1254       2022               MI              FT               Data Engineer   \n",
              "1255       2022               MI              FT  Machine Learning Scientist   \n",
              "\n",
              "        salary salary_currency employee_residence  remote_ratio  \\\n",
              "0      70000.0             EUR                 DE             0   \n",
              "1     260000.0             USD                 JP             0   \n",
              "2      85000.0             GBP                 GB            50   \n",
              "3      20000.0             USD                 HN             0   \n",
              "4     150000.0             USD                 US            50   \n",
              "...        ...             ...                ...           ...   \n",
              "1251   45000.0             GBP                 GB           100   \n",
              "1252  260000.0             USD                 US           100   \n",
              "1253   60000.0             USD                 AR           100   \n",
              "1254   63900.0             USD                 US             0   \n",
              "1255  160000.0             USD                 US           100   \n",
              "\n",
              "     remote_work_type company_location company_size      job_category  \n",
              "0        On-site only               DE            L      Data Science  \n",
              "1        On-site only               JP            S  Machine Learning  \n",
              "2              Hybrid               UK            M  Data Engineering  \n",
              "3        On-site only               HN            S      Data Analyst  \n",
              "4              Hybrid               US            L  Machine Learning  \n",
              "...               ...              ...          ...               ...  \n",
              "1251     Fully remote               UK            M  Data Engineering  \n",
              "1252     Fully remote               US            M      Data Science  \n",
              "1253     Fully remote               MX            L  Data Engineering  \n",
              "1254     On-site only               US            M  Data Engineering  \n",
              "1255     Fully remote               US            L  Machine Learning  \n",
              "\n",
              "[1256 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-25e33e49-cce8-4062-82a7-6cec4b6179bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>work_year</th>\n",
              "      <th>experience_level</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>job_title</th>\n",
              "      <th>salary</th>\n",
              "      <th>salary_currency</th>\n",
              "      <th>employee_residence</th>\n",
              "      <th>remote_ratio</th>\n",
              "      <th>remote_work_type</th>\n",
              "      <th>company_location</th>\n",
              "      <th>company_size</th>\n",
              "      <th>job_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>EUR</td>\n",
              "      <td>DE</td>\n",
              "      <td>0</td>\n",
              "      <td>On-site only</td>\n",
              "      <td>DE</td>\n",
              "      <td>L</td>\n",
              "      <td>Data Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Machine Learning Scientist</td>\n",
              "      <td>260000.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>JP</td>\n",
              "      <td>0</td>\n",
              "      <td>On-site only</td>\n",
              "      <td>JP</td>\n",
              "      <td>S</td>\n",
              "      <td>Machine Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Big Data Engineer</td>\n",
              "      <td>85000.0</td>\n",
              "      <td>GBP</td>\n",
              "      <td>GB</td>\n",
              "      <td>50</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>UK</td>\n",
              "      <td>M</td>\n",
              "      <td>Data Engineering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Product Data Analyst</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>HN</td>\n",
              "      <td>0</td>\n",
              "      <td>On-site only</td>\n",
              "      <td>HN</td>\n",
              "      <td>S</td>\n",
              "      <td>Data Analyst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>150000.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>US</td>\n",
              "      <td>50</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>US</td>\n",
              "      <td>L</td>\n",
              "      <td>Machine Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>2022</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>45000.0</td>\n",
              "      <td>GBP</td>\n",
              "      <td>GB</td>\n",
              "      <td>100</td>\n",
              "      <td>Fully remote</td>\n",
              "      <td>UK</td>\n",
              "      <td>M</td>\n",
              "      <td>Data Engineering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>2022</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>260000.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>US</td>\n",
              "      <td>100</td>\n",
              "      <td>Fully remote</td>\n",
              "      <td>US</td>\n",
              "      <td>M</td>\n",
              "      <td>Data Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>2022</td>\n",
              "      <td>SE</td>\n",
              "      <td>FT</td>\n",
              "      <td>Data Science Engineer</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>AR</td>\n",
              "      <td>100</td>\n",
              "      <td>Fully remote</td>\n",
              "      <td>MX</td>\n",
              "      <td>L</td>\n",
              "      <td>Data Engineering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>2022</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Data Engineer</td>\n",
              "      <td>63900.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>US</td>\n",
              "      <td>0</td>\n",
              "      <td>On-site only</td>\n",
              "      <td>US</td>\n",
              "      <td>M</td>\n",
              "      <td>Data Engineering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>2022</td>\n",
              "      <td>MI</td>\n",
              "      <td>FT</td>\n",
              "      <td>Machine Learning Scientist</td>\n",
              "      <td>160000.0</td>\n",
              "      <td>USD</td>\n",
              "      <td>US</td>\n",
              "      <td>100</td>\n",
              "      <td>Fully remote</td>\n",
              "      <td>US</td>\n",
              "      <td>L</td>\n",
              "      <td>Machine Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1256 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25e33e49-cce8-4062-82a7-6cec4b6179bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8b1f3f77-405d-4369-abc9-15b589b73c7e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b1f3f77-405d-4369-abc9-15b589b73c7e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8b1f3f77-405d-4369-abc9-15b589b73c7e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25e33e49-cce8-4062-82a7-6cec4b6179bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25e33e49-cce8-4062-82a7-6cec4b6179bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our copy, let's begin exploring the data and its structure. Use the summary functions that we learned in `Python 103` to look at the metadata for `ds_salaries_clean` and observe the number of rows, columns, datatypes, and null values:\n"
      ],
      "metadata": {
        "id": "xJJfEnBVCP7r"
      },
      "id": "xJJfEnBVCP7r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the first 5 rows of the data using the `head` method:"
      ],
      "metadata": {
        "id": "YF52QbDl5_j3"
      },
      "id": "YF52QbDl5_j3"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GcHxq5Nm5-jy"
      },
      "id": "GcHxq5Nm5-jy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the total number of null values per column using the `isna` method:"
      ],
      "metadata": {
        "id": "FU8FYX9j6D3z"
      },
      "id": "FU8FYX9j6D3z"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJTbQqwb5s4S"
      },
      "id": "rJTbQqwb5s4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking more closely, we see that there are null values in some columns. Management doesn't want any null values in the cleaned data. But if we just drop all the rows with null values, we'll lose data unneccessarily. We want to keep any data we can and discard only the records we can't reasonably salvage.\n",
        "\n",
        "Let's start with the `salary` column, which has 14 null values. Can we reasonably infer what those missing salaries are?\n",
        "\n",
        "While it's possible to guess what those missing values could be, the results are not guaranteed to be accurate. This could skew our analysis. Also, the rows with missing salaries have missing job titles too, which we would want to know as well. Since there are only 14 rows (~2% of the total data) that are affected, the best approach for our purposes would be to just drop them.\n",
        "\n",
        "Drop the rows with null values in the `salary` column:"
      ],
      "metadata": {
        "id": "2FpTOkYvFFjs"
      },
      "id": "2FpTOkYvFFjs"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6C_03UCH7st"
      },
      "id": "S6C_03UCH7st",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now verify that the rows in the salary column were dropped by checking the null values in `ds_salaries_clean` again:"
      ],
      "metadata": {
        "id": "90MpY7VoKJ8Z"
      },
      "id": "90MpY7VoKJ8Z"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sdCCjE0pKfOx"
      },
      "id": "sdCCjE0pKfOx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test\n",
        "Run the following cell to ensure that you dropped the rows correctly before continuing (There should be no output if correct):"
      ],
      "metadata": {
        "id": "Qmb-fInZb7Uf"
      },
      "id": "Qmb-fInZb7Uf"
    },
    {
      "cell_type": "code",
      "source": [
        "assert ds_salaries_clean.salary.isna().sum() == 0"
      ],
      "metadata": {
        "id": "Rz3Q_8-icBEt"
      },
      "id": "Rz3Q_8-icBEt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've taken care of removing those rows, let's look at the other columns with null values. The `company_size` column has 8 null values. This is another case where we could possibly guess at these values, but for our purposes its better to drop rows where this is null.\n",
        "\n",
        "Go ahead and drop all rows where `company_size` is null:"
      ],
      "metadata": {
        "id": "ywL7YvbiOU8c"
      },
      "id": "ywL7YvbiOU8c"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uRvUOh0oPHoj"
      },
      "id": "uRvUOh0oPHoj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test\n",
        "\n",
        "Run the following code cell to check your work:"
      ],
      "metadata": {
        "id": "mfNjY9jgcblw"
      },
      "id": "mfNjY9jgcblw"
    },
    {
      "cell_type": "code",
      "source": [
        "assert ds_salaries_clean.company_size.isna().sum() == 0"
      ],
      "metadata": {
        "id": "aAhiHFGLceNz"
      },
      "id": "aAhiHFGLceNz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've handled most of the null values in our data so far. The last column that we have to deal with is `remote_work_type`, which has 41 nulls. If we look at both `remote_work_type` and `remote_ratio`, we should see that `remote_work_type` is directly related to the `remote_ratio`. We can determine what the work type is by using the ratio. Since we have all the ratios and are only missing some types, we can fill in the nulls using the `remote_ratio`.\n",
        "\n",
        "Use the example below, which fills in the values for `On-site only` types, to fill in the nulls for `Hybrid` and `Fully remote`:"
      ],
      "metadata": {
        "id": "fG8RVPdFPgYW"
      },
      "id": "fG8RVPdFPgYW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the next cell:"
      ],
      "metadata": {
        "id": "xTFepvKWAR-y"
      },
      "id": "xTFepvKWAR-y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a filter for \"On-site only\" remote ratios\n",
        "onsite_only = ds_salaries_clean.loc[ds_salaries_clean.remote_ratio == 0]\n",
        "# Set the `remote_work_type` values for the data found by the filter to \"On-site only\"\n",
        "ds_salaries_clean.loc[onsite_only.index, 'remote_work_type'] = 'On-site only'"
      ],
      "metadata": {
        "id": "nFbxFaaDQv4o"
      },
      "id": "nFbxFaaDQv4o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Answer here"
      ],
      "metadata": {
        "id": "1sl46zTNTAcT"
      },
      "id": "1sl46zTNTAcT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test\n",
        "\n",
        "After filling in the missing values for `remote_work_type`, there should be no more null values in the data. Run the cell below to confirm that your work is correct so far:"
      ],
      "metadata": {
        "id": "rGkRUwg4SnKd"
      },
      "id": "rGkRUwg4SnKd"
    },
    {
      "cell_type": "code",
      "source": [
        "# There are no nulls in remote_work_type\n",
        "assert ds_salaries_clean.remote_work_type.isna().sum() == 0\n",
        "# The values in remote_work_type were created correctly\n",
        "values = list(ds_salaries_clean.remote_work_type.unique())\n",
        "values_check = ['On-site only', 'Fully remote', 'Hybrid']\n",
        "assert  len(values) == len(values_check) and len([i for i in values if i in values_check]) == 3\n",
        "# There are no more null values in ds_salaries_clean\n",
        "assert ds_salaries_clean.isna().sum().sum() == 0"
      ],
      "metadata": {
        "id": "4lbGvIJpS592"
      },
      "id": "4lbGvIJpS592",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "062dbe6c",
      "metadata": {
        "id": "062dbe6c"
      },
      "source": [
        "Great work!\n",
        "\n",
        "The nulls are taken care of, but there is an issue with the `salary` column - these salaries are all in different currencies! Good thing we have the `usd_exchange_rates` table. We can use that data to convert all the `salary` information in `ds_salaries_clean` to USD for consistency.\n",
        "\n",
        "First, familiarize yourself with `usd_exchange_rates` by looking at the data and checking the column definitions in the Data Dictionary supplied by management:"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rkbu9sn6XlPl"
      },
      "id": "Rkbu9sn6XlPl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you're familiar with the `usd_exchange_rates`, it's time to join it to `ds_salaries_clean`. Fill in the code below to join the two tables:"
      ],
      "metadata": {
        "id": "08vM81XDXlg7"
      },
      "id": "08vM81XDXlg7"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_salaries_clean = pd.function_to_join(\n",
        "    ds_salaries_clean,\n",
        "    usd_exchange_rates,\n",
        "    left_on = [\"Columns to join from ds_salaries_clean\"],\n",
        "    right_on = [\"Columns to join from usd_exchange_rates\"]\n",
        ")"
      ],
      "metadata": {
        "id": "89xX3x1eYF4f"
      },
      "id": "89xX3x1eYF4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our data merged, it's time to convert the salary. Create a new column called `salary_in_usd` that is the result of the `salary` divided by `exchange_rate`.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "# Note: The `round` function can be used to round your results\n",
        "df.loc[:, 'new_column'] = round(df['col1'] / df['col2'])\n",
        "```"
      ],
      "metadata": {
        "id": "9VqAXuGjZE6N"
      },
      "id": "9VqAXuGjZE6N"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvT801YlSfC6"
      },
      "id": "jvT801YlSfC6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9b3f2a0b",
      "metadata": {
        "id": "9b3f2a0b"
      },
      "source": [
        "Great! Now we have a uniform way to measure the salary information.\n",
        "\n",
        "Before we finish cleaning, there are a few columns with abbreviations (`experience_level`, `employment_type`, and `company_location`). We should have the full names of these terms as columns in the cleaned data set.\n",
        "\n",
        "Using the data dictionary and the `merge` function, join the `experience_levels`, `employment_types`, and `countries` data into `ds_salaries_clean` to translate the abbreviations:\n",
        "\n",
        "Example:\n",
        "```python\n",
        "df = pd.merge(df, df2, left_on=\"df_col\", right_on=\"df2_col\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-fQUFDhCuKNF"
      },
      "id": "-fQUFDhCuKNF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2557f18a",
      "metadata": {
        "id": "2557f18a"
      },
      "source": [
        "Ok, now we're almost done cleaning. But if we look at `ds_salaries_clean`, there are some extra columns we don't need that were added from the joins we just did.\n",
        "\n",
        "Drop the following columns:\n",
        "\n",
        "`abbreviation_x`,`abbreviation_y`, `abbreviation`, `iso_code`, `ref_date`"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BZOMNs6vEwo"
      },
      "id": "0BZOMNs6vEwo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test\n",
        "\n",
        "Run the cell below to confirm the columns were dropped correctly:"
      ],
      "metadata": {
        "id": "6ug-gnow4uNz"
      },
      "id": "6ug-gnow4uNz"
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_cols = ['abbreviation_x','abbreviation_y', 'abbreviation', 'iso_code', 'ref_date']\n",
        "assert len([i for i in ds_salaries_clean if i in dropped_cols]) == 0"
      ],
      "metadata": {
        "id": "TgOl27yJ4uUR"
      },
      "id": "TgOl27yJ4uUR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've handled all the nulls, added columns with more information, and mostly cleaned our data. The only thing that's left is to remove any duplicate rows. Go ahead and drop the duplicates using the `drop_duplicates` method on `ds_salaries_clean`:"
      ],
      "metadata": {
        "id": "zB0FQlmS3tdi"
      },
      "id": "zB0FQlmS3tdi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s3I0Tj8A4GCI"
      },
      "id": "s3I0Tj8A4GCI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1ce3445",
      "metadata": {
        "id": "d1ce3445"
      },
      "source": [
        "Great work!\n",
        "\n",
        "Now the data should be clean and ready for analysis! Run the next cell as one last test before writing the new table as a `csv` and starting your analysis:\n",
        "\n",
        "\n",
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2860ea",
      "metadata": {
        "id": "9c2860ea"
      },
      "outputs": [],
      "source": [
        "# Test for null values\n",
        "assert ds_salaries_clean.isna().sum().sum() == 0\n",
        "# Test for duplicates\n",
        "assert ds_salaries_clean.duplicated().sum() == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65efa406",
      "metadata": {
        "id": "65efa406"
      },
      "source": [
        "If the tests in the cell above pass, you're ready to do your analysis! Let's write the cleaned table to a csv file first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6069d653",
      "metadata": {
        "id": "6069d653"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This line is meant to write their `clean` dataframe to a csv file for submission. This will save\n",
        "the file in the same folder where this notebook is located. The file name will be `ds_salaries_clean.csv`.\n",
        "\n",
        "For students using Google Colab, the file will be saved to the folder space accessed via the menu on the\n",
        "left side of the screen. They can download the file to their local machine from there.\n",
        "\"\"\"\n",
        "\n",
        "ds_salaries_clean.to_csv(\"ds_salaries_clean.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f60373",
      "metadata": {
        "id": "59f60373"
      },
      "source": [
        "## Part Two: Analysis\n",
        "\n",
        "Now it's time to start analyzing the data and answering the questions from management. If you haven't done so yet, familiarize yourself with the questions and data dictionary to get a better sense of the data.\n",
        "\n",
        "The questions asked mostly involve summarizing parts of the data and reporting your findings. You will be doing a lot of aggregate functions (get your `groupby` ready!)\n",
        "\n",
        "Unlike the previous section, this one is not as guided. You will get some hints, but you are expected to answer the questions using your existing `Python` and/or `SQL` knowledge along with help from Google and the other resources provided.\n",
        "\n",
        "You can use `SQL` to query the data to get the answers, or you can use `Python` only, or a combination of both.\n",
        "\n",
        "There are only two rules:\n",
        "\n",
        "1. You must create at least 3 visuals using `matplotlib`\n",
        "2. If you answer a question using `SQL` only, still create a new `pandas` DataFrame that has the results of your query\n",
        "\n",
        " Example:\n",
        " ```python\n",
        " # Create a new DataFrame from a SQL query\n",
        " my_query = \"\"\"\n",
        "      SELECT *\n",
        "      FROM ds_salaries\n",
        " \"\"\"\n",
        " new_df = pd.read_sql(my_query, con=engine)\n",
        " ```\n",
        "\n",
        "Now on to the questions!\n",
        "\n",
        "\n",
        "*Note: There is a table in the database called `ds_salaries_clean` that is a copy of the cleaned table that you should use for your queries if you're using `SQL`*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436f8534",
      "metadata": {
        "id": "436f8534"
      },
      "source": [
        "### What is the average overall salary (regardless of year) by job category?\n",
        "\n",
        ">*Hint*:\n",
        ">\n",
        ">*One of the keywords in this question is `by`. When you see this, it indicates that you'll need to summarize the data by the field(s) that comes after `by`. You'll have to use `groupby` and an aggregate function to solve this.*\n",
        ">\n",
        ">*Make sure to order the results so that it's easy to see the largest salaries vs the smallest. This way answers are clearly visible.*\n",
        ">\n",
        ">*Also, use the `round` function to format your salary results to make them look neater!*\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xNUvTUTeI66b"
      },
      "id": "xNUvTUTeI66b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7f4e9494",
      "metadata": {
        "id": "7f4e9494"
      },
      "source": [
        "### What is the average salary by job category and experience level (regardless of year)?\n",
        "\n",
        ">*Hint*:\n",
        ">\n",
        ">*This is similar to the first question, except instead of grouping by one column, you're grouping by two. Order your results by `job_category`*\n",
        ">\n",
        ">*Also, use the `round` function to format your salary results to make them look neater!*\n",
        ">\n",
        ">*This will be tough to make a visual for since we didn't go over subplots. If you want to challenge yourself, go ahead and look up tutorials on how to do this! But be mindful of time and consider using a table to visualize this*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgS33JwYBQbA"
      },
      "id": "fgS33JwYBQbA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6af276a4",
      "metadata": {
        "id": "6af276a4"
      },
      "source": [
        "### In which country do data analysts make the most money on average? Which country do they make the least?\n",
        "\n",
        ">*Hint*:\n",
        ">\n",
        ">*This is a filtering and aggregation problem. While we don't have the `by` keyword here, the question asks us to look at average salary for data analysts in each country. We are  filtering for data analysts and grouping salaries by country.*\n",
        ">\n",
        ">*Filter the data by `Data Analyst` and then get the average salary by country for that subset. Finally, we want to see the min and max values for this subset. Solving to get just the min and max values is a bit more complex than what we've learned so far. It is OK to show the entire list (ordered, of course) and highlight the highest and lowest values in your response.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9ZJh1WsBRF_"
      },
      "id": "o9ZJh1WsBRF_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bff295c5",
      "metadata": {
        "id": "bff295c5"
      },
      "source": [
        "### Which job category earns more on average: Data Analyst, Data Science, or Data Engineering?\n",
        "\n",
        ">*Hint*:\n",
        ">\n",
        ">*Another filtering and aggregation problem. This time we're looking at average salary by specific job categories. Use the same pattern as the previous filtering/aggregation questions that we answered to complete this.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZtLVxa7BRqZ"
      },
      "id": "YZtLVxa7BRqZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bedc2b7a",
      "metadata": {
        "id": "bedc2b7a"
      },
      "source": [
        "### Which company size pays data professionals the most on average? Is there a relationship between company size and average pay?\n",
        "\n",
        ">*Hint:*\n",
        ">\n",
        ">*This is an aggregation problem with an additional question that can only be answered following the aggregation. Follow the same pattern as the previous questions and use the results to determine whether there is a relationship between pay and company size.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDn9R6PSn1a6"
      },
      "id": "LDn9R6PSn1a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9ac2f48f",
      "metadata": {
        "id": "9ac2f48f"
      },
      "source": [
        "### Which job category pays the most on average in 2022?\n",
        "\n",
        ">*Hint:*\n",
        ">\n",
        ">*This is another filtering and aggregation problem. Apply the same pattern you've used previously to solve this. You should return only the job category with the highest average pay in 2022*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtmD_V4KsPVP"
      },
      "id": "UtmD_V4KsPVP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "91a48b66",
      "metadata": {
        "id": "91a48b66"
      },
      "source": [
        "### How are companies working in 2022 (Remote, In-Office, Hybrid)?\n",
        "\n",
        ">*Hint:*\n",
        ">\n",
        ">*This is also a filtering and aggregation problem (a fairly common theme.) Apply the same pattern you've used previously to solve this.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CEviGLvjvN9o"
      },
      "id": "CEviGLvjvN9o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f6345826",
      "metadata": {
        "id": "f6345826"
      },
      "source": [
        "### What additional analysis/insights can you make using the dataset?\n",
        "\n",
        ">*Hint:*\n",
        ">\n",
        ">*Here's your chance to provide management with unique input or insight based on what you have found in the database to management.*\n",
        ">\n",
        ">*This is an optional question, but we encourage you to explore the data for relationships or patterns that were not asked about but may be relevant.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562baa69",
      "metadata": {
        "id": "562baa69"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This is an optional and totally open ended question. It's not necessarily meant to be graded but rather\n",
        "to challenge students to think beyond the outline we gave them\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40a52092",
      "metadata": {
        "id": "40a52092"
      },
      "source": [
        "## Part Three: Delivering Results\n",
        "\n",
        "You've cleaned the data, answered your manager's questions, and created some visualizations to share your insights. Job well done! Now its time to send the results to your manager.\n",
        "\n",
        "Compose an email response to your manager's request. Provide an overview of the analysis you did and the materials you are submitting for their review. Attach a copy of the `ds_salaries_clean` data set, as well as this notebook, to the email and send it to your pod captain."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J3H1bo7mDWN3"
      },
      "id": "J3H1bo7mDWN3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}